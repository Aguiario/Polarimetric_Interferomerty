{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyPI as pi\n",
    "import numpy as np\n",
    "from scipy.linalg import eig\n",
    "import sympy as sp\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85355339-0.14644661j, 0.35355339+0.35355339j],\n",
       "       [0.35355339+0.35355339j, 0.14644661-0.85355339j]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectores de entrada y salida\n",
    "E_in = pi.polarization_basis_set('L')\n",
    "S = pi.jones_matrix(np.pi/2, np.pi/8)\n",
    "E_out = S @ E_in\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "α: 0.1250π\n"
     ]
    }
   ],
   "source": [
    "# Componentes principale\n",
    "# Cálculo de autovalores y autovectores\n",
    "eigenvalues, eigenvectors = eig(S)\n",
    "\n",
    "# Determinación de alpha a partir del autovector principal\n",
    "alpha_calculado = np.arctan2(np.real(eigenvectors[1, 0]), np.real(eigenvectors[0, 0]))\n",
    "\n",
    "# Resultados\n",
    "#print(\"Autovector principal (dirección dominante):\\n\", eigenvectors[:, 0])\n",
    "print(f\"α: {alpha_calculado/np.pi:.4f}π\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "χ: 0.5000π\n",
      "α: 0.1250π\n"
     ]
    }
   ],
   "source": [
    "# Matriz por minimizacion\n",
    "optimal_delta_chi, optimal_alpha = pi.birefringence_by_minimization(E_in, E_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False],\n",
       "       [False, False]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = E_out @ np.linalg.pinv(E_in)  # Uso de la pseudoinversa para mayor robustez\n",
    "M == S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz M optimizada:\n",
      "[[ 0.46102798-0.62217828j  0.82925937-0.03895334j]\n",
      " [-0.00711608-0.22346206j  0.72348786-1.21422683j]]\n",
      "Error mínimo alcanzado: 2.9075595897906606e-05\n"
     ]
    }
   ],
   "source": [
    "# Función de error para minimizar la diferencia entre la salida calculada y la esperada\n",
    "def error_function(params):\n",
    "    m_11 = params[0] + 1j * params[1]\n",
    "    m_12 = params[2] + 1j * params[3]\n",
    "    m_21 = params[4] + 1j * params[5]\n",
    "    m_22 = params[6] + 1j * params[7]\n",
    "    \n",
    "    M = np.array([[m_11, m_12],\n",
    "                  [m_21, m_22]], dtype=np.complex128)\n",
    "    \n",
    "    result = M @ E_in  # Estado de polarización calculado\n",
    "    return np.linalg.norm(result - E_out)  # Métrica de error\n",
    "\n",
    "# Suposición inicial para el proceso de minimización\n",
    "initial_guess = [0, 0, 0, 0, 0, 0, 0, 0]  # Inicializa todas las componentes en cero\n",
    "\n",
    "# Proceso de minimización usando el método Nelder-Mead\n",
    "result = minimize(error_function, initial_guess, method='Nelder-Mead')\n",
    "\n",
    "# Extraer parámetros optimizados\n",
    "m_11 = result.x[0] + 1j * result.x[1]\n",
    "m_12 = result.x[2] + 1j * result.x[3]\n",
    "m_21 = result.x[4] + 1j * result.x[5]\n",
    "m_22 = result.x[6] + 1j * result.x[7]\n",
    "\n",
    "# Matriz M optimizada\n",
    "M = np.array([[m_11, m_12],\n",
    "              [m_21, m_22]], dtype=np.complex128)\n",
    "\n",
    "print(\"Matriz M optimizada:\")\n",
    "print(M)\n",
    "print(f\"Error mínimo alcanzado: {result.fun}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25      +0.10355339j, -0.10355339+0.25j      ],\n",
       "       [ 0.60355339+0.25j      , -0.25      +0.60355339j]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metodos mas robustos?\n",
    "# Pseudoinversa Regularizada (Recomendada para datos ruidosos o mal condicionados)\n",
    "import numpy as np\n",
    "from scipy.linalg import svd\n",
    "\n",
    "def robust_pinv(E_in, epsilon=1e-10):\n",
    "    U, S, Vh = svd(E_in)  # Descomposición en valores singulares\n",
    "    S_inv = np.diag(1 / S) if S.ndim == 1 else np.diag([1/s if s > epsilon else 0 for s in S])\n",
    "    \n",
    "    # Expandir `S_inv` para que tenga las dimensiones correctas\n",
    "    S_inv_expanded = np.zeros_like(E_in.T)\n",
    "    np.fill_diagonal(S_inv_expanded, [1/s if s > epsilon else 0 for s in S])\n",
    "    \n",
    "    return Vh.T @ S_inv_expanded @ U.T\n",
    "\n",
    "M_PR = E_out @ robust_pinv(E_in)\n",
    "M_PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 250.        +103.55339059j, -103.55339059+250.j        ],\n",
       "       [ 603.55339059+250.j        , -250.        +603.55339059j]])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Método de Tikhonov Regularizado (Ridge Regression) \n",
    "from scipy.linalg import solve\n",
    "\n",
    "alpha = 1e-3  # Parámetro de regularización\n",
    "M_TR = E_out @ np.linalg.inv(E_in.T @ E_in + alpha * np.eye(E_in.shape[1])) @ E_in.T\n",
    "M_TR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.25      +0.10355339j, -0.10355339+0.25j      ],\n",
       "       [ 0.60355339+0.25j      , -0.25      +0.60355339j]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Descomposición QR (Robusta para matrices mal condicionadas)\n",
    "Q, R = np.linalg.qr(E_in)\n",
    "M_QR = E_out @ np.linalg.inv(R) @ Q.T\n",
    "M_QR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.20710678],\n",
       "       [1.20710678, 0.5       ]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Método de Levenberg-Marquardt (Preciso y estable en sistemas no lineales o inestables)\n",
    "from scipy.optimize import least_squares\n",
    "\n",
    "# Función de error desglosada en partes reales e imaginarias\n",
    "def residuals(M_flat):\n",
    "    M = M_flat.reshape(2, 2)  # Reconstruir la matriz\n",
    "    error = M @ E_in - E_out\n",
    "    return np.concatenate([error.real.ravel(), error.imag.ravel()])  # Aplanar el error\n",
    "\n",
    "# Suposición inicial\n",
    "initial_guess = np.random.rand(4)  # 4 elementos para una matriz 2x2\n",
    "\n",
    "# Método de Levenberg-Marquardt\n",
    "result = least_squares(residuals, initial_guess, method='lm')\n",
    "\n",
    "# Reconstruir la matriz resultante\n",
    "M_LM = result.x.reshape(2, 2)\n",
    "M_LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25      +0.10355339j, 0.10355339-0.25j      ],\n",
       "       [0.60355339+0.25j      , 0.25      -0.60355339j]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reducción del Condicionamiento mediante Escalado (Para evitar pérdida de precisión)\n",
    "scale_factor = np.linalg.norm(E_in)\n",
    "M_RE = (E_out / scale_factor) @ np.linalg.pinv(E_in / scale_factor)\n",
    "M_RE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
